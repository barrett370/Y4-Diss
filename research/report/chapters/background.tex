\section{Genetic Algorithms}

\subsection{History}

Genetic algorithms are a type of meta-heuristic optimisation technique that employ the same rationale as classical Evolution seen in nature.

Genetic Algorithms can trace their origins back to the late 1960s when they were first proposed by John Holland, though he then referred to them as \textit{Genetic Plans}\footnote{This distinction was made to emphasise the \textit{"centrality of computation in defining and implementing the plans"}\cite{hollandAdaptationNaturalArtificial1992a}}. Holland went on to write the first book on the subject titled \textit{Adaptation in Natural and Artificial Systems}\cite{hollandAdaptationNaturalArtificial1992a} in 1975. The field did not find much reception with Holland stating in the preface to the 1992 rerun:

\begin{displayquote}
\textit{``When this book was originally published I was very optimistic, envisioning extensive reviews and a kind of 'best seller' in the realm of monographs. Alas! That did not happen.``}
\end{displayquote}

However, in the early nineties, Genetic algorithms surged in popularity along with the area of Artificially Intelligent planning as a whole leading to Holland republishing his book and solidifying his position as the field's founder.

\subsection{Definition}
In a general sense, optimisation techniques work to find the set of parameters $\mathcal{P}$ that minimise an objective function $\mathcal{F}$. 
Genetic algorithms approach this by representing these sets as individuals in a population, $P$. Over the course of multiple generations, the best solutions are determined and promoted until termination criteria are met or the maximum number of generations is reached.

As our candidates are essentially a collection of parameters to the function we are trying to optimise, we can extend our metaphor further by mapping each element of a individual to a \textit{gene} in a individual's genome. 

The representation we use in a GA is problem specific. Often we have to provide functions to facilitate the mapping between the problem specific set of possible solutions and the encoded genotype space in which we optimise. The most basic representation being a string of binary numbers.

An individual's characteristics and genetic information is normally encapsulated within the Phenotype. Here not only the genetic information of the Genotype but also additional information, such as fitness, is stored in order to prevent it from being re-calculated as often.

Genetic algorithms are both \textit{probabilistically optimal} and \textit{probabilistically complete}\cite{kalaOnroadIntelligentVehicles2016} meaning that: given infinite time, not only will the algorithm find \textit{a} solution, (if one exists), it will find \textbf{the} optimal solution from the set of all possible solutions, $\mathcal{P}^*$.

\begin{algorithm}[H]
	\label{alg:GenericGA}
	\SetAlgoLined
	\KwResult{Best Solution, $p_{ \texttt{best}}$}	
	Generate initial population, $P_0$ of size $n$\;
	Evaluate fitness of each individual in $P_0$, $\{F(p_{0,1},\ldots, p_{0,n})\}$\;
	\While{termination criteria are not met}{
		\textbf{Selection}: Select individuals from $P_t$ based on their fitness\;
		\textbf{Variation}: Apply variation operators to parents from $P_t$ to produce offspring\;
		\textbf{Evaluation}: Evaluate the fitness of the newly bred individuals\;
		\textbf{Reproduction}: Generate a new population $P_{t+1}$ using individuals from $P_t$ as well as the newly bred candidates.\;
		$t$++
	}
	return $p_{\texttt{best}}$

	\caption{Modern Generic Genetic Algorithm}
\end{algorithm}

\begin{figure}[htpb]
    \centering
    \includegraphics[width=\linewidth]{hollandAlg}
    \caption{GA algorithm outlined in Holland's Original Book\cite{hollandAdaptationNaturalArtificial1992a}}
    \label{fig:hollandAlg}
\end{figure}

As you can see from Figure \ref{fig:hollandAlg} and Algorithm \ref{alg:GenericGA} the overall shape of GAs has not changed substantially over the course of the past 50 years. Being comprised of a series of operations that a starting population is piped through until criteria are met.

\subsection{Genetic Operators}\todo{Expand definitions of operators used in implementation section}

In the following section I will outline the various genetic operations that take place in a GA, they can be seen in Algorithm~\ref{alg:GenericGA}. Any operators used and analysed in Chapter~\ref{chap:ClassicalApproach} will have more detailed explanations of their process.

\subsubsection{Selection}

The selection procedure is the process by which the next generation of individuals is created from the current population. Individuals are selected relative to their fitness as determined by the Objective (fitness) function $\mathcal{F}$. 

Some methods select only the best solutions by fitness. Others employ a more stochastic approach, such as roulette wheel selection, to increase diversity and reduce complexity.

\paragraph{Fitness Proportional Selection}

Fitness proportional or Roulette wheel selection is a popular selection operator. It uses fitness to assign selection probability to each individual in a population.

The probability of selection for an individual $i$ with fitness $\mathcal{F}(i)$ can be expressed mathematically as:

\begin{equation}
    p_i = \frac{\mathcal{F}(i)}{ \sum^{N}_{j=1} \mathcal{F}(j)} 
\end{equation}

Where $N$ is the size of the population $P$

This is a simple approach but performs well and has very little performance overhead.  

\subsubsection{Variation}

Variation in a GA is the process of altering the genome individuals to further explore the search space via stochastic local search.
We perform this using two distinct sub-operations: Mutation and Crossover.
Here we can view crossover as the \textit{breeding} process and mutation as resembling the natural tendency for DNA to mutate over the course of generations.

\paragraph{Mutation}
In mutation we alter each gene with a set probability $p_m$ known as the \textit{mutation rate}. A standard value for a mutation rate is $ \frac{1}{L} $ but it can fall anywhere in the range $p_m \in [ \frac{1}{L} , \frac{1}{2} ] $ where $L$ is the length of the genome.

A low value for $p_m$ a new individual which can be shown to be \textit{close} to it's parents in the search space relative to their \textit{Hamming distance}\footnote{Hamming Distance: The metric for comparing two binary data strings. The Hamming distance between two strings is the number of bit position in which they differ.} if using a Binary coded GA. In real-coded GAs they can be shown to be close by the Euclidean distance between them.

In binary coded GAs we alter a given gene by \textit{flipping} it's value.
In real-coded GAs mutation operators include: 
\begin{itemize}
    \item Uniform Mutation
    \item Non-Uniform Mutation
    \item Gaussian Mutation 
\end{itemize}
\subparagraph{Uniform Mutation}
In uniform mutation, we select a parent, $p$, and replace a randomly selected gene $c_i \in p$ with a uniformly random number $c_i' \in [u_i,v_i]$  where $u_i$ and $v_i$ are set bounds.


\paragraph{Crossover}

Crossover is a binary operation, taking two randomly selected \textit{parents} from the population $P_t$ with a probability $p_c \in [0,1]$ 

There are two major forms of crossover for binary coded GAs: $n>1$ point crossover and Uniform crossover. 

For real-coded GAs you instead have a selection of Crossover operators including:

\begin{itemize}
    \item Flat crossover
    \item Simple crossover
    \item Whole arithmetic crossover
    \item Local arithmetic crossover
    \item Single arithmetic crossover
    \item BLX-$\alpha$ crossover
\end{itemize}


\subparagraph{Simple (one point) Crossover}

For simple crossover, randomly select a crossover point, $i \in \{1,\ldots,n \}$. All values before this point are swapped between the two parents. For 2 parents, $p_1 = \left\{ x_1^{[1]},\ldots,x_n^{[1]}\right\}$ and $p_2 = \left\{ x_1^{[2]},\ldots,x_n^{[2]}\right\}$ this can be represented as:

\begin{equation}
    p_1' = \left\{ x_1^{[1]},x_2^{[1]}, \ldots, x_i^{[1]}, x_{i+1}^{[2]},\ldots, x_n^{[2]} \right\} 
\end{equation}

\begin{equation}
    p_2' = \left\{ x_1^{[2]},x_2^{[2]}, \ldots, x_i^{[2]}, x_{i+1}^{[1]},\ldots, x_n^{[1]} \right\}
\end{equation}

\subsubsection{Evaluation}
After developing potential new individuals, the fitness of these new individuals is calculated using the objective function, $\mathcal{F}$

\subsubsection{Reproduction}
Here the next generation of individuals is constructed. There are multiple potential methods employed here with the simplest being to just replace the lest fit individuals with additional copies of the fitter individuals, be they pre-existing or newly generated.

In this stage various heuristics or alternative strategies can be implemented to speed up or slow down the convergence rate. Whilst their fitness may be low, having a diverse population allows for more of the search space to be explored. If the algorithm converges too quickly it may get \textit{stuck} in local minima. 


\subsection{Bézier Curves}

In my implementation, I utilise Bézier curves to encode complex route arcs between a series of points. Here I will briefly outline their construction and mathematical basis.

Bézier curves were popularised by and named after French auto-body\footnote{so I feel it is quite fitting that they find use in $21^{st}$ century automotive problems} designer Pierre Bézier in the 1960s and are commonly found in computer graphics today. They are parametric curves made up of a series of \textit{control points} which contort the shape of a line to produce a curve of nearly any shape. Although their mathematical basis was established in 1912 by Sergei Bernstein in the form of Bernstein polynomials\cite{bernstein1912best}.

A Bézier curve is said to have a degree of $n-1$ where $n$ is the number of control points including the start and end point of the curve.

\subsubsection{Formal Definition} 

Bézier curves can be simply explicitly defined for degrees of 1 through 4, however, the general case of $n$ points is more useful to us. In their general form they can be defined recursively or explicitly. I implement the recursive version as it is much more readable for a programming language that supports recursion.

They are defined recursively as follows:

\begin{equation}
    \textbf{B}_{P_0}(t) = P_0
\end{equation}

\begin{equation}
    \textbf{B}_{P_0,P_1,\ldots,P_n}(t) = (1-t)\textbf{B}_{P_0,P_1,\ldots,P_{n-1}}(t) + t\textbf{B}_{P_1,P_2,\ldots,P_n}(t)
\end{equation}

Where the parameter $t$ is in the range of $[0,1]$. Therefore, the smoothness of the curve is determined by the granularity of the parameter when realising the curve.

\section{Fully Autonomous Road Networks}

Fully autonomous road networks are by no means a novel concept. They have appeared in fiction since the mid 20th century and have been a real possibility for the past decade. In a fully autonomous road networks \textit{(FARN)}s, all vehicles are self-operating with their routing either being determined on a vehicle-by-vehicle \textit{selfish} basis or by a larger system managing routes for all nearby agents. 

In the latter system protocols that promote the net increase in efficiency can be implemented. However, this sort of system will require a form of government mandate as a universal routing protocol would need to be established and implemented by all auto manufacturers; this is no small undertaking.


