\subsection{Genetic Algorithms}

The core of my approach to solving the problems outlined in Chapter~\ref{chap:Intro} was creating a Genetic algorithm to evolve populations of candidate routes, returning the fittest once the termination criteria are met.

GAs are transparent, probabilistic approaches to optimisation problems. As such, it is much easier to reason about and predict their output when compared with more traditional \textit{black box} approaches such as neural networks.

Whilst a poor choice of training data can lead to unintended/ unpredictable behaviour from approaches like neural networks, they have the advantage that most of their compute time is used when constructing the initial model, subsequent usage of these models requires little compute time. Whereas, GAs must run the entirety of the \textit{learning} process from scratch whenever a new route or set of routes is required. In an application where the system sees a high number of unique requests, this compute time can quickly amount to much longer than the training time for a neural network.

\subsection{Genetic Operator Performance}

During development I implemented two different operators in each category, but there are many other approaches proposed in academic literature. Given more time, I would have liked to implement more and present a more empirical evaluation of each.

\subsubsection{Selection}

In a single generation, over three populations of 15 individuals, my ranked selection operator ran 3 times totalling $97.4\mu s$ or an average of $32.5\mu s$ per run.

As you can see in Figure~\ref{fig:selection_eg}, my ranked selection operator performs its task well, removing the obviously less fit individuals in favour of more copies of  fitter ones. This can be seen by the removal of the line that dips below the $x$ axis (in this example the bottom road boundary was defined as $b_{1}(x) = 0 $) and the fact that duplicate routes are found as indicated by the 3rd graph of unique routes showing fewer individuals than the second.

Ranked selection compared with fitness proportional (roulette wheel selection) is much more predictable, it may not explore as much of the search space but it is more likely to thoroughly explore a single area. Most other selection operators seem to focus on maintaining a diverse population so as to not get stuck in local minima.

\subsubsection{Mutation}

The mutation operators I implemented were Uniform and Gaussian.

I found Gaussian to perform better in cases where a route may be close to optimal in the phenotypic space, i.e. with minimal changes to trajectory, it would be optimal. In such cases the genotypic fitness may not accurately represent this, a route that collides with another or passes through infeasible space will suffer from a large genotypic fitness penalty possibly encouraging it to be removed from the \textit{gene pool}. Gaussian mutation, preferring mutated points closer to their initial position can be effective as moving such routes closer to the optima.

However, in cases where the initial population generation has created all routes far from the optimal, Gaussian mutation can struggle to generate mutated points extreme enough to direct the GA towards the minima.

Part of the problem with Gaussian mutation, and mutation in general on $n$-degree Bezier curves, is that even a relatively major control point movement may cause only minor changes to the overall trajectory of the curve in cases where $n$ is high.

An example of a relatively large control point mutation leading to a minor direction change can be seen in Figure~\ref{fig:gauss_mutation_eg}.

It is possible that an approach incorporating Simulated Annealing could help to broadly explore the search space in early generations before refining solutions in a found minima in latter generations.

In a single generation, over the same 3 sets of 15 individuals, my Gaussian mutation operator ran 3 times totalling $1.8 ms$ runtime, an average of $601 \mu s$. This is an insignificant amount of time when compared to the overall runtime of this task which stands at $38.8s$.

\subsection{Bézier Curves}
\todo[inline]{expand on this section, talk about issues of finding intersection, possible GPU applications}

Bézier curves have been utilised in this project to encode and represent the route of a vehicle. As mentioned in Section~\ref{sec:back-bezier-curves}, there are many reasons I originally selected them for this task. However, over the course of implementation and testing, a number of downsides have been presented.

\begin{enumerate}
  \item Objective\todo{correct word?} numerical approaches with Bézier curves are often complicated, expensive and do not generalise well to $n$ control points.

        This leads to many heuristics, and approximations being employed to save computation. Approximations and assumptions in a system as the one proposed in this report, are sub-optimal and could potentially lead of undesired behaviour which could ultimately have dire consequences if such a system were to be deployed.

        Other research such as that by Cai \& Peng\cite{caiCooperativeCoevolutionaryAdaptive2002} takes a different approach, using discrete, grid-based search spaces in which routes are made up of a series of connected straight line segments. This approach removes much of the complexity from my solution but introduces its own concerns.

        The routes generated by Cai \& Peng's approach are intended to be executed by autonomous robots, so no thought has been given to potential passengers. Consequently, these routes would require smoothing as a post-planning process, re-introducing complexity.

        Another possible representation is the approach taken by Cruz-Piris et al.\cite{cruz-pirisAutomatedOptimizationIntersections2019} which involved representing the section of road, in their case an intersection, as a cellular automata in which a single vehicle can occupy a single cell at any given point in time. \end{enumerate}\todo{does this need to be an enumerated list?}


There were however, also some advantages and nice properties of Bézier curves which lent themselves to the task.

Their relatively simple abstract construction as a series of control points proved easy to concretely represent as a genotype. This made the creation of the various genetic operators relatively simple, requiring little pre or post-processing.

They are also capable of representing a high complexity of curve in a relatively simple and concise manner. This makes code much more approachable and algorithms easier to digest.

\subsection{Cooperative Planning}
\label{subsec:eval-cooperativeplanning}

My solution to the problem of planning $n$ non-colliding routes for $n$ agents was so wrap my existing \texttt{GA} function in a cooperative \textit{layer}. This cooperative layer relied on a function for detecting collisions which had extremely high overhead, at one point causing around 50x slowdown in the running time of the function. Detecting intersections between two Bézier curves is a non-trivial task with the best methods taking the same approach of recursive subdivision that I utilised.

\todo[inline]{make mention of possible GPU implementations such at in~\cite{robergeFastGeneticAlgorithm2018}, modern enterprise GPUs have around 4000-10000 cores, approximately the max number of curve splits and comparisons in a binary check of depth 6. Being able to do this in a single cycle would result in a huge speedup, paper uses Titan X }



%TC:macro \todo 1

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "report"
%%% End:
